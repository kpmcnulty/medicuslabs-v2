# MedicusLabs v2 - Medical Data Aggregation Platform

A simplified, high-performance platform for aggregating, searching, and analyzing medical data from multiple sources including ClinicalTrials.gov, PubMed, FDA FAERS, and medical forums. Built with FastAPI, React, and PostgreSQL.

## ğŸš€ Quick Start

### Prerequisites
- Docker and Docker Compose
- Git
- 4GB+ RAM recommended
- 10GB+ disk space for data storage

### Initial Setup

1. **Clone the repository:**
```bash
git clone <repository-url>
cd medicuslabs-v2
```

2. **Create environment file:**
```bash
cp .env.example .env
# Edit .env if needed (default values work for local development)
```

3. **Build and start services:**
```bash
docker-compose up -d --build
```

4. **Access the platform:**
- **Frontend**: http://localhost:3000
- **Admin Portal**: http://localhost:3000/admin (default: admin/admin123)
- **API Documentation**: http://localhost:8000/docs
- **API Health Check**: http://localhost:8000/health

## ğŸ— Architecture

### Simplified Stack
- **Frontend**: React + TypeScript (port 3000)
- **Backend**: FastAPI + Python 3.11 (port 8000)
- **Database**: PostgreSQL 15 + pgvector (port 5432)

That's it! No Redis, no Celery, no message queues. Just three lean containers.

### Key Features
- **Unified Search**: Single endpoint with keyword search and metadata filtering
- **Direct Scraper Execution**: Scrapers run inline via FastAPI BackgroundTasks
- **Admin Portal**: Manage sources, diseases, and monitor scraping jobs
- **Real-time Search**: PostgreSQL full-text search with sub-second queries
- **Flexible Metadata**: JSONB storage for source-specific fields

## ğŸ“ Project Structure

```
medicuslabs-v2/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ scrapers.py          # Scraper triggers (BackgroundTasks)
â”‚   â”‚   â”œâ”€â”€ search_unified.py    # Main search endpoint (~400 lines)
â”‚   â”‚   â”œâ”€â”€ metadata.py          # Field metadata
â”‚   â”‚   â””â”€â”€ admin/               # Admin endpoints (Dashboard, Sources, Diseases)
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ auth.py             # JWT authentication
â”‚   â”‚   â”œâ”€â”€ config.py           # Settings
â”‚   â”‚   â””â”€â”€ database.py         # DB connection
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ database.py         # Document, Source, Disease models
â”‚   â””â”€â”€ scrapers/
â”‚       â”œâ”€â”€ base.py             # Base scraper
â”‚       â”œâ”€â”€ clinicaltrials.py   # ClinicalTrials.gov
â”‚       â”œâ”€â”€ pubmed.py           # PubMed
â”‚       â”œâ”€â”€ faers.py            # FDA FAERS
â”‚       â”œâ”€â”€ reddit.py           # Reddit medical subs
â”‚       â””â”€â”€ web.py              # Generic web scraper
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ components/
â”‚       â”‚   â”œâ”€â”€ admin/          # Admin interface
â”‚       â”‚   â”œâ”€â”€ DiseaseDataByType.tsx
â”‚       â”‚   â””â”€â”€ filters/
â”‚       â””â”€â”€ hooks/
â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ schema.sql              # Main schema
â”‚   â””â”€â”€ migrations/             # Database migrations
â””â”€â”€ docker-compose.yml          # 3 services: postgres, api, frontend
```

## ğŸ”Œ API Endpoints

### Core Search
- `GET /health` - Health check
- `POST /api/search/unified` - Main search endpoint
- `GET /api/search/filters` - Available filters (sources, diseases, categories)

### Scrapers
- `GET /api/scrapers/sources` - List all sources
- `POST /api/scrapers/trigger` - Trigger scraping job (runs in background)
- `GET /api/scrapers/jobs` - List scraping jobs
- `GET /api/scrapers/jobs/{job_id}` - Get job status

### Admin (JWT Protected)
- `POST /api/admin/login` - Admin authentication
- `GET /api/admin/dashboard/stats` - Dashboard statistics
- `GET /api/admin/sources` - Manage data sources
- `GET /api/admin/diseases` - Manage diseases

## ğŸ” Admin Authentication

Default credentials: `admin` / `admin123`

Change password via environment variable:
```bash
# Generate bcrypt hash
python -c "from passlib.hash import bcrypt; print(bcrypt.hash('your-password'))"

# Add to .env
ADMIN_PASSWORD_HASH=<bcrypt-hash>
```

## ğŸ§¬ Data Sources

| Source | Type | Documents Available |
|--------|------|---------------------|
| ClinicalTrials.gov | Trials | 600K+ |
| PubMed | Publications | 35M+ |
| FDA FAERS | Adverse Events | 20M+ |
| Reddit Medical | Community | 10+ subreddits |
| Web Scraper | Custom | Configurable |

## ğŸ›  Development

### Basic Commands
```bash
# Start all services
docker-compose up -d

# Stop services
docker-compose down

# View logs
docker-compose logs -f api
docker-compose logs -f frontend
docker-compose logs -f postgres

# Restart a service
docker-compose restart api

# Access database
docker-compose exec postgres psql -U medical_user -d medical_data

# Access API shell
docker-compose exec api bash
```

### Manual Scraping
```bash
# Trigger via API (requires admin token)
curl -X POST http://localhost:8000/api/scrapers/trigger \
  -H "Content-Type: application/json" \
  -d '{
    "source_name": "PubMed",
    "disease_ids": [1],
    "options": {"max_results": 100}
  }'
```

## ğŸ” Search Examples

### Keyword Search
```bash
curl -X POST http://localhost:8000/api/search/unified \
  -H "Content-Type: application/json" \
  -d '{
    "q": "diabetes treatment",
    "limit": 50
  }'
```

### Filtered Search
```bash
curl -X POST http://localhost:8000/api/search/unified \
  -H "Content-Type: application/json" \
  -d '{
    "q": "cancer",
    "sources": ["PubMed", "ClinicalTrials.gov"],
    "diseases": ["Lung Cancer"],
    "metadata": {
      "phase": {"$gte": 3}
    },
    "limit": 50
  }'
```

## ğŸš€ Performance

- **Search Latency**: ~200ms average
- **Documents**: Scalable to millions with partitioning
- **Concurrent Users**: 100+ supported
- **Database**: Indexed for common queries

## ğŸ“ What Changed (Cleanup)

This version removes complexity while keeping core functionality:

**Removed:**
- âŒ Redis (caching layer)
- âŒ Celery (task queue)
- âŒ Flower (Celery monitoring)
- âŒ Nginx (reverse proxy)
- âŒ Hybrid/semantic search (vector embeddings)
- âŒ Jobs/Schedules admin pages

**Kept:**
- âœ… All scrapers (ClinicalTrials, PubMed, FAERS, Reddit, Web)
- âœ… Full-text search with PostgreSQL
- âœ… Admin portal (Dashboard, Sources, Diseases)
- âœ… Keyword + metadata filtering
- âœ… JSONB metadata storage
- âœ… Background task execution

**How scrapers work now:**
- Triggered via API endpoint
- Run in background via FastAPI BackgroundTasks
- Update job status in database
- Simple, no external queue needed

## ğŸ†˜ Troubleshooting

### Services won't start
```bash
# Check what's using ports
lsof -i :3000  # Frontend
lsof -i :8000  # API
lsof -i :5432  # PostgreSQL

# Clean restart
docker-compose down -v
docker-compose up -d --build
```

### No search results
```bash
# Check if documents exist
docker-compose exec postgres psql -U medical_user -d medical_data -c "SELECT COUNT(*) FROM documents;"

# Trigger test scrape via admin portal
# Or use API to trigger scraping
```

### Database issues
```bash
# Check database is ready
docker-compose exec postgres pg_isready

# View tables
docker-compose exec postgres psql -U medical_user -d medical_data -c "\dt"

# Run migrations manually
docker-compose exec postgres psql -U medical_user -d medical_data -f /docker-entrypoint-initdb.d/schema.sql
```

## ğŸ“„ License

MIT License - see LICENSE file for details.

---

*Simple, fast, and maintainable. Built for real-world medical research.*
